rhos <- data.frame(id = 1:length(rhos), rhos)
rhos <- rhos[order(-rhos$rhos),]
#Set up a juxtaposed plot area for six graphs
par(mfrow=c(2,3),
oma = c(5,4,0,0) + 0.5,
mar = c(0,0,1,1) + 0.5)
#Plot the LASSO
plot(y.test, type = "l", col = "grey", main = paste0("LASSO: RMSE = ", err1),
cex.main = 1.2, ylab = "outcome", xaxt='n', yaxt = 'n')
lines(yhat.test, col = "red")
#Loop through and plot top X correlates using OLS
for(i in c(1, 2, 3, 5, 10)){
#Set up data
df.train <- data.frame(y.train, x.train[,rhos$id[1:i]])
df.test <- data.frame(y.test, x.test[,rhos$id[1:i]])
colnames(df.train) <- colnames(df.test) <- c("y", paste0("x",1:i))
#Model
lm.obj <- lm(y~., data = df.train)
yhat2 <- predict(lm.obj, newdata = df.test)
#Plot y
err2 <- round(rmse(yhat2, y.test),2)
plot(y.test, type = "l", col = "grey", main = paste0("Top ", i," Only: RMSE = ", err2),
ylab = "outcome", cex.main = 1.2, xaxt='n', yaxt = 'n')
lines(yhat2, col = "red")
}
library(digIt)
flu <- digIt("flu")
sample(colnames(flu), 20, replace = FALSE)
#Calculate correlation matrix
mat <- cor(flu[,ncol(flu):2])
#Extract correlates with ILI
top <- data.frame(query = row.names(mat),
rho = mat[,1])
top <- top[order(-top$rho),]
row.names(top) <- NULL
#Show top five
knitr::kable(head(top, 10), booktab = TRUE)
library(glmnet)
#Set sample partition parameters
train.prop <- 0.75
train.max <- round(nrow(flu) * train.prop)
test.min <- train.max + 1
#Train
y.train <- flu$ili.rate[1:train.max]
x.train <- flu[1:train.max,]
x.train$date <- x.train$ili.rate <- NULL
x.train <- as.matrix(x.train)
#Test
y.test <- flu$ili.rate[test.min:nrow(flu)]
x.test <- flu[test.min:nrow(flu), ]
x.test$date <- x.test$ili.rate <- NULL
x.test <- as.matrix(x.test)
mod.lasso <- cv.glmnet(x.train, y.train, nfolds = 20,
alpha = 1, type.measure = "mse")
plot(mod.lasso)
#Coefficiets
a <- coef(mod.lasso,  s = "lambda.min")
b <- coef(mod.lasso,  s = c( 0.05, 0.5), exact = TRUE)
tab <- data.frame(Variable = row.names(a), coef1 = a[,1], coef2 = b[,1], coef3 = b[,2])
row.names(tab) <- NULL
tab <- tab[tab$coef2 != 0,]
tab <- tab[order(-tab$coef2),]
for(i in 2:4){
tab[,i] <- round(tab[,i],5)
tab[tab[,i]==0,i] <- ""
}
knitr::kable(tab, booktab = TRUE, row.names = FALSE, col.names =  c("Feature", paste0("Lambda Min = ", round(mod.lasso$lambda.min, 3)), "Lambda = 0.05", "Lambda = 0.5"))
#Predict y
yhat.train <- predict(mod.lasso, x.train, s = "lambda.min")
yhat.test <- predict(mod.lasso, x.test, s = "lambda.min")
#Calculate out of sample error
rmse <- function(y, x){
return(sqrt(mean((y - x)^2)))
}
err1 <- round(rmse(yhat.test, y.test),2)
print(err1)
#Calculate correlation matrix using training data
rhos <- as.vector(cor(y.train, x.train))
rhos <- data.frame(id = 1:length(rhos), rhos)
rhos <- rhos[order(-rhos$rhos),]
#Set up a juxtaposed plot area for six graphs
par(mfrow=c(2,3),
oma = c(5,4,0,0) + 0.5,
mar = c(0,0,1,1) + 0.5)
#Plot the LASSO
plot(y.test, type = "l", col = "grey", main = paste0("LASSO: RMSE = ", err1),
cex.main = 1.2, ylab = "outcome", xaxt='n', yaxt = 'n')
lines(yhat.test, col = "red")
#Loop through and plot top X correlates using OLS
for(i in c(1, 2, 3, 5, 10)){
#Set up data
df.train <- data.frame(y.train, x.train[,rhos$id[1:i]])
df.test <- data.frame(y.test, x.test[,rhos$id[1:i]])
colnames(df.train) <- colnames(df.test) <- c("y", paste0("x",1:i))
#Model
lm.obj <- lm(y~., data = df.train)
yhat2 <- predict(lm.obj, newdata = df.test)
#Plot y
err2 <- round(rmse(yhat2, y.test),2)
plot(y.test, type = "l", col = "grey", main = paste0("Top ", i," Only: RMSE = ", err2),
ylab = "outcome", cex.main = 1.2, xaxt='n', yaxt = 'n')
lines(yhat2, col = "red")
}
library(digIt)
flu <- digIt("flu")
sample(colnames(flu), 20, replace = FALSE)
#Calculate correlation matrix
mat <- cor(flu[,ncol(flu):2])
#Extract correlates with ILI
top <- data.frame(query = row.names(mat),
rho = mat[,1])
top <- top[order(-top$rho),]
row.names(top) <- NULL
#Show top five
knitr::kable(head(top, 10), booktab = TRUE)
library(glmnet)
#Set sample partition parameters
train.prop <- 0.8
train.max <- round(nrow(flu) * train.prop)
test.min <- train.max + 1
#Train
y.train <- flu$ili.rate[1:train.max]
x.train <- flu[1:train.max,]
x.train$date <- x.train$ili.rate <- NULL
x.train <- as.matrix(x.train)
#Test
y.test <- flu$ili.rate[test.min:nrow(flu)]
x.test <- flu[test.min:nrow(flu), ]
x.test$date <- x.test$ili.rate <- NULL
x.test <- as.matrix(x.test)
mod.lasso <- cv.glmnet(x.train, y.train, nfolds = 20,
alpha = 1, type.measure = "mse")
plot(mod.lasso)
#Coefficiets
a <- coef(mod.lasso,  s = "lambda.min")
b <- coef(mod.lasso,  s = c( 0.05, 0.5), exact = TRUE)
tab <- data.frame(Variable = row.names(a), coef1 = a[,1], coef2 = b[,1], coef3 = b[,2])
row.names(tab) <- NULL
tab <- tab[tab$coef2 != 0,]
tab <- tab[order(-tab$coef2),]
for(i in 2:4){
tab[,i] <- round(tab[,i],5)
tab[tab[,i]==0,i] <- ""
}
knitr::kable(tab, booktab = TRUE, row.names = FALSE, col.names =  c("Feature", paste0("Lambda Min = ", round(mod.lasso$lambda.min, 3)), "Lambda = 0.05", "Lambda = 0.5"))
#Predict y
yhat.train <- predict(mod.lasso, x.train, s = "lambda.min")
yhat.test <- predict(mod.lasso, x.test, s = "lambda.min")
#Calculate out of sample error
rmse <- function(y, x){
return(sqrt(mean((y - x)^2)))
}
err1 <- round(rmse(yhat.test, y.test),2)
print(err1)
#Calculate correlation matrix using training data
rhos <- as.vector(cor(y.train, x.train))
rhos <- data.frame(id = 1:length(rhos), rhos)
rhos <- rhos[order(-rhos$rhos),]
#Set up a juxtaposed plot area for six graphs
par(mfrow=c(2,3),
oma = c(5,4,0,0) + 0.5,
mar = c(0,0,1,1) + 0.5)
#Plot the LASSO
plot(y.test, type = "l", col = "grey", main = paste0("LASSO: RMSE = ", err1),
cex.main = 1.2, ylab = "outcome", xaxt='n', yaxt = 'n')
lines(yhat.test, col = "red")
#Loop through and plot top X correlates using OLS
for(i in c(1, 2, 3, 5, 10)){
#Set up data
df.train <- data.frame(y.train, x.train[,rhos$id[1:i]])
df.test <- data.frame(y.test, x.test[,rhos$id[1:i]])
colnames(df.train) <- colnames(df.test) <- c("y", paste0("x",1:i))
#Model
lm.obj <- lm(y~., data = df.train)
yhat2 <- predict(lm.obj, newdata = df.test)
#Plot y
err2 <- round(rmse(yhat2, y.test),2)
plot(y.test, type = "l", col = "grey", main = paste0("Top ", i," Only: RMSE = ", err2),
ylab = "outcome", cex.main = 1.2, xaxt='n', yaxt = 'n')
lines(yhat2, col = "red")
}
library(digIt)
flu <- digIt("flu")
sample(colnames(flu), 20, replace = FALSE)
#Calculate correlation matrix
mat <- cor(flu[,ncol(flu):2])
#Extract correlates with ILI
top <- data.frame(query = row.names(mat),
rho = mat[,1])
top <- top[order(-top$rho),]
row.names(top) <- NULL
#Show top five
knitr::kable(head(top, 10), booktab = TRUE)
library(glmnet)
#Set sample partition parameters
train.prop <- 0.9
train.max <- round(nrow(flu) * train.prop)
test.min <- train.max + 1
#Train
y.train <- flu$ili.rate[1:train.max]
x.train <- flu[1:train.max,]
x.train$date <- x.train$ili.rate <- NULL
x.train <- as.matrix(x.train)
#Test
y.test <- flu$ili.rate[test.min:nrow(flu)]
x.test <- flu[test.min:nrow(flu), ]
x.test$date <- x.test$ili.rate <- NULL
x.test <- as.matrix(x.test)
mod.lasso <- cv.glmnet(x.train, y.train, nfolds = 20,
alpha = 1, type.measure = "mse")
plot(mod.lasso)
#Coefficiets
a <- coef(mod.lasso,  s = "lambda.min")
b <- coef(mod.lasso,  s = c( 0.05, 0.5), exact = TRUE)
tab <- data.frame(Variable = row.names(a), coef1 = a[,1], coef2 = b[,1], coef3 = b[,2])
row.names(tab) <- NULL
tab <- tab[tab$coef2 != 0,]
tab <- tab[order(-tab$coef2),]
for(i in 2:4){
tab[,i] <- round(tab[,i],5)
tab[tab[,i]==0,i] <- ""
}
knitr::kable(tab, booktab = TRUE, row.names = FALSE, col.names =  c("Feature", paste0("Lambda Min = ", round(mod.lasso$lambda.min, 3)), "Lambda = 0.05", "Lambda = 0.5"))
#Predict y
yhat.train <- predict(mod.lasso, x.train, s = "lambda.min")
yhat.test <- predict(mod.lasso, x.test, s = "lambda.min")
#Calculate out of sample error
rmse <- function(y, x){
return(sqrt(mean((y - x)^2)))
}
err1 <- round(rmse(yhat.test, y.test),2)
print(err1)
#Calculate correlation matrix using training data
rhos <- as.vector(cor(y.train, x.train))
rhos <- data.frame(id = 1:length(rhos), rhos)
rhos <- rhos[order(-rhos$rhos),]
#Set up a juxtaposed plot area for six graphs
par(mfrow=c(2,3),
oma = c(5,4,0,0) + 0.5,
mar = c(0,0,1,1) + 0.5)
#Plot the LASSO
plot(y.test, type = "l", col = "grey", main = paste0("LASSO: RMSE = ", err1),
cex.main = 1.2, ylab = "outcome", xaxt='n', yaxt = 'n')
lines(yhat.test, col = "red")
#Loop through and plot top X correlates using OLS
for(i in c(1, 2, 3, 5, 10)){
#Set up data
df.train <- data.frame(y.train, x.train[,rhos$id[1:i]])
df.test <- data.frame(y.test, x.test[,rhos$id[1:i]])
colnames(df.train) <- colnames(df.test) <- c("y", paste0("x",1:i))
#Model
lm.obj <- lm(y~., data = df.train)
yhat2 <- predict(lm.obj, newdata = df.test)
#Plot y
err2 <- round(rmse(yhat2, y.test),2)
plot(y.test, type = "l", col = "grey", main = paste0("Top ", i," Only: RMSE = ", err2),
ylab = "outcome", cex.main = 1.2, xaxt='n', yaxt = 'n')
lines(yhat2, col = "red")
}
library(digIt)
flu <- digIt("flu")
sample(colnames(flu), 20, replace = FALSE)
#Calculate correlation matrix
mat <- cor(flu[,ncol(flu):2])
#Extract correlates with ILI
top <- data.frame(query = row.names(mat),
rho = mat[,1])
top <- top[order(-top$rho),]
row.names(top) <- NULL
#Show top five
knitr::kable(head(top, 10), booktab = TRUE)
library(glmnet)
#Set sample partition parameters
train.prop <- 0.75
train.max <- round(nrow(flu) * train.prop)
test.min <- train.max + 1
#Train
y.train <- flu$ili.rate[1:train.max]
x.train <- flu[1:train.max,]
x.train$date <- x.train$ili.rate <- NULL
x.train <- as.matrix(x.train)
#Test
y.test <- flu$ili.rate[test.min:nrow(flu)]
x.test <- flu[test.min:nrow(flu), ]
x.test$date <- x.test$ili.rate <- NULL
x.test <- as.matrix(x.test)
mod.lasso <- cv.glmnet(x.train, y.train, nfolds = 20,
alpha = 1, type.measure = "mse")
plot(mod.lasso)
#Coefficiets
a <- coef(mod.lasso,  s = "lambda.min")
b <- coef(mod.lasso,  s = c( 0.05, 0.5), exact = TRUE)
tab <- data.frame(Variable = row.names(a), coef1 = a[,1], coef2 = b[,1], coef3 = b[,2])
row.names(tab) <- NULL
tab <- tab[tab$coef2 != 0,]
tab <- tab[order(-tab$coef2),]
for(i in 2:4){
tab[,i] <- round(tab[,i],5)
tab[tab[,i]==0,i] <- ""
}
knitr::kable(tab, booktab = TRUE, row.names = FALSE, col.names =  c("Feature", paste0("Lambda Min = ", round(mod.lasso$lambda.min, 3)), "Lambda = 0.05", "Lambda = 0.5"))
#Predict y
yhat.train <- predict(mod.lasso, x.train, s = "lambda.min")
yhat.test <- predict(mod.lasso, x.test, s = "lambda.min")
#Calculate out of sample error
rmse <- function(y, x){
return(sqrt(mean((y - x)^2)))
}
err1 <- round(rmse(yhat.test, y.test),2)
print(err1)
#Calculate correlation matrix using training data
rhos <- as.vector(cor(y.train, x.train))
rhos <- data.frame(id = 1:length(rhos), rhos)
rhos <- rhos[order(-rhos$rhos),]
#Set up a juxtaposed plot area for six graphs
par(mfrow=c(2,3),
oma = c(5,4,0,0) + 0.5,
mar = c(0,0,1,1) + 0.5)
#Plot the LASSO
plot(y.test, type = "l", col = "grey", main = paste0("LASSO: RMSE = ", err1),
cex.main = 1.2, ylab = "outcome", xaxt='n', yaxt = 'n')
lines(yhat.test, col = "red")
#Loop through and plot top X correlates using OLS
for(i in c(1, 2, 3, 5, 10)){
#Set up data
df.train <- data.frame(y.train, x.train[,rhos$id[1:i]])
df.test <- data.frame(y.test, x.test[,rhos$id[1:i]])
colnames(df.train) <- colnames(df.test) <- c("y", paste0("x",1:i))
#Model
lm.obj <- lm(y~., data = df.train)
yhat2 <- predict(lm.obj, newdata = df.test)
#Plot y
err2 <- round(rmse(yhat2, y.test),2)
plot(y.test, type = "l", col = "grey", main = paste0("Top ", i," Only: RMSE = ", err2),
ylab = "outcome", cex.main = 1.2, xaxt='n', yaxt = 'n')
lines(yhat2, col = "red")
}
##########################
##LECTURE 6: KNN Example##
##########################
#Load in data
dir <- "/Users/jeff/Documents/Github/data-science/lecture-06/data"
setwd(dir)
df <- read.csv("ndvi_sample_201606.csv")
#Take a look at the imagery
library(ggplot2)
ggplot(df, aes(x=lon, y=lat)) +
geom_raster(aes(fill = ndvi)) +
ggtitle("NDVI: October 2016") +
scale_fill_gradientn(limits = c(-1,1), colours = rev(terrain.colors(10)))
#Cut down file to US
#Subset image to Western US near the Rocky Mountains
us_west <- df[df$lat < 45 & df$lat > 35 &  df$lon > -119 & df$lon < -107,]
#Randomly selection a 30% sample
set.seed(32)
sampled <- us_west[runif(nrow(us_west)) < 0.3 & us_west$ndvi != 99999,]
#KNN regression function
knn.mean <- function(x_train, y_train, x_test, k){
#Set vector of length of test set
output <-  vector(length = nrow(x_test))
#Loop through each row of the test set
for(i in 1:nrow(x_test)){
#extract coords for the ith row
cent <- x_test[i,]
#Set vector length
dist <- vector(length = nrow(x_train))
#Calculate distance by looping through inputs
for(j in 1:ncol(x_train)){
dist <- dist + (x_train[, j] - cent[j])^2
}
dist <- sqrt(dist)
#Calculate rank on ascending distance, sort by rank
df <- data.frame(id = 1:nrow(x_train),rank = rank(dist))
df <- df[order(df$rank),]
#Calculate mean of obs in positions 1:k, store as i-th value in output
output[i] <- mean(y_train[df[1:k,1]], na.rm=T)
}
return(output)
}
#Optimization code
knn.opt <- function(x_train, y_train, x_test, y_test, max, step){
#create log placehodler
log <- data.frame()
for(i in seq(1, max, step)){
#Run KNN for value i
yhat <- knn.mean(x_train, y_train, x_test, i)
#Calculate RMSE
rmse <- round(sqrt(mean((yhat  - y_test)^2, na.rm=T)), 3)
#Add result to log
log <- rbind(log, data.frame(k = i, rmse = rmse))
}
#sort log
log <- log[order(log$rmse),]
#return log
return(log)
}
#SET UP TRAIN/TEST
#Set up data
set.seed(123)
rand <- runif(nrow(sampled))
#training set
xtrain <- as.matrix(sampled[rand < 0.7, c(1,2)])
ytrain <- sampled[rand < 0.7, 3]
#test set
xtest <- as.matrix(sampled[rand >= 0.7, c(1,2)])
ytest <- sampled[rand >= 0.7, 3]
#Optimize KNN at one k increments
logs <- knn.opt(xtrain, ytrain, xtest, ytest, nrow(xtest), 1)
#Plot results
ggplot(logs, aes(x = k, y = rmse)) +
geom_line() + geom_point() + ggtitle("RMSE vs. K-Nearest Neighbors")
#Comparisons
#Original
full <- ggplot(us_west, aes(x=lon, y=lat)) +
geom_raster(aes(fill = ndvi)) +
ggtitle("Original NASA Tile") +
scale_fill_gradientn(limits = c(-1,1), colours = rev(terrain.colors(10)))
#30% sample
sampled <- ggplot(sampled, aes(x=lon, y=lat)) +
geom_raster(aes(fill = ndvi)) +
ggtitle("Sample: 30%") +
scale_fill_gradientn(limits = c(-1,1), colours = rev(terrain.colors(10)))
#Set new test set
xtest <- as.matrix(us_west[, c(1,2)])
#Test k for four different values
for(k in c(1, 4, 10, 100)){
yhat <- knn.mean(xtrain,ytrain,xtest, k)
pred <- data.frame(xtest, ndvi = yhat)
rmse <- round(sqrt(mean((yhat  - us_west$ndvi)^2, na.rm=T)), 3)
g <- ggplot(pred, aes(x=lon, y=lat)) +
geom_raster(aes(fill = ndvi)) +
ggtitle(paste0("kNN (k =",k,", RMSE = ", rmse,")")) +
scale_fill_gradientn(limits = c(-1,1), colours = rev(terrain.colors(10)))
assign(paste0("k",k), g)
}
#Graphs plotted
library(gridExtra)
grid.arrange(full, sampled, k1, k4, k10, k100, ncol=2)
210/24
setwd("/Users/jeff/Documents/Github/data-science/lecture-10/data")
list.files()
a <- read.csv(list.files())
complaints <- read.csv(list.files())
View(complaints)
complaints <- readRDS("cfpb_complaints.Rda")
complaints <- readRDS("cfpb_complaints.Rds")
complaints <- readRDS("cfpb_complaints.rds")
getwd()
list.files()
saveRDS(complaints, "cfpb_complaints.rds")
complaints <- readRDS("cfpb_complaints.rds")
########################################
##getTAL. Download episode transcripts##
########################################
getTAL <- function(ep.num){
# A function to download episode transcripts from ThisAmericanLife.org
#
# Args:
#       ep.num: an integer corresponding to an episode number
#
# Returns:
#       A list containing two data farmes: an episode table and a transcript table
#
#Readlines to find content IDs
library(rvest)
library(RCurl)
#Create URL
urlTAL <- paste0("https://www.thisamericanlife.org/radio-archives/episode/",ep.num,"/transcript")
#Check if episode transcript exists
check <- url.exists(urlTAL)
if(check){
a <- readLines(urlTAL)
#title
title <- grep("<a href=\"/radio-archives/episode/", a, value = TRUE)[1]
title <- substr(title, regexpr(">", title)+1,regexpr("</a>",title)-1)
#date
radiodate <- grep("class=\"radio\\-date\"",a, value = TRUE)
date <- regmatches(radiodate, regexpr("\\d{2}\\.\\d{2}\\.\\d{4}",radiodate))
meta <- data.frame(title = title,
link = urlTAL,
date = date,
ep.num = ep.num,
available = TRUE)
scraped <- read_html(urlTAL)
output <- data.frame()
#get text
b <- grep("\"act\"",a, value = TRUE)
c <- paste0("#",gsub("[[:punct:]]","", gsub("^id","", regmatches(b,regexpr("id=\"[[:alnum:]]{1,100}\"",b)))))
for(k in 1:length(c)){
temp <- scraped %>%
html_nodes(c[k]) %>% html_text()
output <- rbind(output,
data.frame(ep.num = ep.num,
tag = c[k],
text = unlist(temp)))
}
} else {
meta <- data.frame(title = NA,
date = NA,
ep.num = ep.num,
available = FALSE)
output <- data.frame(ep.num = ep.num,
tag = NA,
text = NA)
}
return(list(meta, output))
}
a <- getTAL(620)
a <- getTAL(1)
ep.num = 1
urlTAL <- paste0("https://www.thisamericanlife.org/radio-archives/episode/",ep.num,"/transcript")
urlTAL
