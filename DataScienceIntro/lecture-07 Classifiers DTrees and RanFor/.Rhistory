summary(pred.glm.train)
#plotROC
library(plotROC)
library(ggplot2)
input.glm <- rbind(data.frame(model = "train", d = train$coverage, m = pred.glm.train),
data.frame(model = "test", d = test$coverage,  m = pred.glm.test))
scores <- rbind(scores, data.frame(model = "GLM", d = test$coverage,  m = pred.glm.test >= 0.5))
roc.glm <- ggplot(input.glm, aes(d = d, model = model, m = m, colour = model)) +
geom_roc(show.legend = TRUE) + style_roc()  + ggtitle("ROC: GLM")
calc_auc(roc.glm)[,2:3]
#Mean F1
pred.labels <- pred.glm.test > 0.5
pred.labels[pred.labels==TRUE ] <- "No Coverage"
pred.labels[pred.labels==FALSE ] <- "Coverage"
meanf1(test$coverage, pred.labels)
library(e1071)
library(e1071)
data("AirPassengers")
AP <- AirPassengers
class(AP)
start(AP); end(AP); frequency(AP)
summary(AP)
plot(AP, ylab = "Passengers (1000's)")
layout(1:2)
plot(aggregate(AP))
boxplot(AP~cycle(AP))
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/Maine.dat"
Maine.month <- read.table(www, header=TRUE)
attach(Maine.month)
class(Maine.month)
Maine.month.ts <- ts(unemploy, start=c(1996,1), freq=12)
Maine.annual.ts <- aggregate(Maine.month.ts)/12
par(mar = rep(2, 4))
layout(1:2)
plot(Maine.month.ts, ylab="unemployed (%)")
plot(Maine.annual.ts, ylab="unemployed (%)")
Maine.Feb <- window(Maine.month.ts, start=c(1996,2), freq=TRUE)
Maine.Aug <- window(Maine.month.ts, start=c(1996,8), freq=TRUE)
Feb.ratio <- mean(Maine.Feb) / mean(Maine.month.ts)
Aug.ratio <- mean(Maine.Aug)/mean(Maine.month.ts)
Feb.ratio
Aug.ratio
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/USunemp.dat"
US.month <- read.table(www, header=T)
attach(US.month)
US.month.ts <- ts(USun, start=c(1996,1), end=c(2006,10), freq=12)
plot(US.month.ts,ylab="unemployed(%)")
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/cbe.dat"
CBE <- read.table(www,header=T)
CBE[1:4,]
class(CBE)
plot(decompose(Elec.ts))
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/pounds_nz.dat"
Z <- read.table(www, header=T)
Z[1:4,]
Z.ts <- ts(Z, st=1991, fr=4)
plot(Z.ts, xlab="time/years",
ylab="Quarterly exchange rate in $NZ/pound")
Z.92.96 <- window(Z.ts, start=c(1992,1), end=c(1996,1))
Z.96.98 <- window(Z.ts, start=c(1996,1), end=c(1998,1))
layout(1:2)
plot(Z.92.96, ylab="Exchange rate in $NZ/pound", xlab="Time (years)")
plot(Z.96.98, ylab="Exchange rate in $NZ/pound", xlab="Time(years")
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/global.dat"
Global <- scan(www)
Global.ts <- ts(Global, st=c(1856,1), end=c(2005,12), fr=12)
Global.annual <- aggregate(Global.ts, FUN = mean)
plot(Global.annual)
plot(decompose(Elec.ts))
# Working with multiple time series
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/cbe.dat"
CBE <- read.table(www,header=T)
CBE[1:4,]
class(CBE)
# To create separate time series for each independent variable
Elec.ts <- ts(CBE[,3], start=1958, freq=12)
Beer.ts <- ts(CBE[,2], start=1958, freq=12)
Choc.ts <- ts(CBE[,1], start=1958, freq=12)
#To plot multiple TS at same time. Alternatively, can use ts.intersect to obtain the intersection of the two series if they overlap in time.
plot(cbind(Elec.ts, Beer.ts, Choc.ts))
# For two series that overlap in time
AP.elec <- ts.intersect(AP,Elec.ts)
start(AP.elec)
end(AP.elec)
AP.elec[1:3,]
# To extract and plot data for both of the series in the intersection
AP <- AP.elec[,1]
Elec <- AP.elec[,2]
layout(1:2)
plot(AP, main="",ylab="Air passengers/1000's")
plot(Elec, main="", ylab="Electricity Production/MkWh")
# as.vector is needed to convert the ts object to ordinary vectors suitable for a scatter plot.
plot(as.vector(AP), as.vector(Elec),
xlab="Air passengers/1000's",
ylab="Electricity production/MWh")
abline(reg=lm(Elec~AP))
# Quarterly exchange rates
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/pounds_nz.dat"
Z <- read.table(www, header=T)
Z[1:4,]
# We use 4 for the frequency below because we're concerned with quarterly data
Z.ts <- ts(Z, st=1991, fr=4)
plot(Z.ts, xlab="time/years",
ylab="Quarterly exchange rate in $NZ/pound")
# To deal with stochastic trends, we usually use a random walk model. Stochastic trends are common in financial series.
Z.92.96 <- window(Z.ts, start=c(1992,1), end=c(1996,1))
Z.96.98 <- window(Z.ts, start=c(1996,1), end=c(1998,1))
layout(1:2)
plot(Z.92.96, ylab="Exchange rate in $NZ/pound", xlab="Time (years)")
plot(Z.96.98, ylab="Exchange rate in $NZ/pound", xlab="Time(years")
# Global temperature time series
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/global.dat"
# Scan is used to read data into a vector or list from the console or file. It is evidently a way of reading columnar data.
Global <- scan(www)
Global.ts <- ts(Global, st=c(1856,1), end=c(2005,12), fr=12)
# Because the trend is what we care about here, the aggregate function is used to remove any seasonal effects within each year and produce an annual series of mean temperatures. (Even if the data set is monthly.)
Global.annual <- aggregate(Global.ts, FUN = mean)
# When you plot in TS, X is always the time, which is known in the plot by virtue of having already made what you are plotting a TS object
plot(Global.annual)
# To extract the monthly time intervals corresponding to the 36-year period. window is a generic function which extracts the subset of the object x observed between the times start and end.
New.series <- window(Global.ts, start=c(1970,1))
# Time subsequently creates he vector of times at which a time series was sampled above.
New.time <- time(New.series)
plot(New.series); abline(reg=lm(New.series~New.time))
## Fitting Time Series Models ##
# TS Forcast model: {xt:t=1,...,n},xhatt+k|t
# Additide Decomposition Model: xt=mt+st+zt where at time t, xt is the observed series, mt is the trend, st is the seasonal effect, and zt is an error term that is, in general, a sequence of correlated random variables with mean zero
# How do we extract the trend mt and the seasonal effect st?
# A moving average is an average of a specified number of time series values around each value in the time series, with the exception of the first few and last few terms. The goal is to average out the effects of the seasonal effects. What we want is a centered moving average.
# Smoothing -> The centered moving average is an example of this
# stl uses a locally weighted regression technique known as loess, but it does not produce a formula that can be extracted for forecasting
# In R, the function decompose estimates trends and seasonal effects using a moving average method.
# So we can next stl within plot by doing plot(stl()) and show the smoothed annual trends with marks for the monthly trends.
plot(decompose(Elec.ts))
Elec.decom <- decompose(Elec.ts, type = "mult")
plot(Elec.decom)
plot(decompose(Elec.ts))
plot(Elec.decom)
plot(decompose(Elec.ts))
plot(Elec.decom)
Trend <- Elec.decom$trend
Seasonal <- Elec.decom$seasonal
ts.plot(cbind(Trend,Trend*Seasonal),lty=1:2)
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/cbe.dat"
CBE <- read.table(www,header=T)
View(CBE)
CBE[1:4,]
class(CBE)
Elec.ts <- ts(CBE[,3], start=1958, freq=12)
Elec.ts
plot(cbind(Elec.ts, Beer.ts, Choc.ts))
AP.elec <- ts.intersect(AP,Elec.ts)
start(AP.elec)
end(AP.elec)
AP.elec[1:3,]
# To extract and plot data for both of the series in the intersection
AP <- AP.elec[,1]
Elec <- AP.elec[,2]
layout(1:2)
plot(AP, main="",ylab="Air passengers/1000's")
plot(Elec, main="", ylab="Electricity Production/MkWh")
# as.vector is needed to convert the ts object to ordinary vectors suitable for a scatter plot.
plot(as.vector(AP), as.vector(Elec),
xlab="Air passengers/1000's",
ylab="Electricity production/MWh")
abline(reg=lm(Elec~AP))
Global <- scan(www)
# Global temperature time series
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/global.dat"
# Scan is used to read data into a vector or list from the console or file. It is evidently a way of reading columnar data.
Global <- scan(www)
Global.ts <- ts(Global, st=c(1856,1), end=c(2005,12), fr=12)
Global.ts
plot(decompose(Elec.ts))
Elec.decom <- decompose(Elec.ts, type = "mult")
x <- c(-50, 175, 149, 214, 247, 237, 225, 329, 729, 809,
530, 489, 540, 457, 195, 176, 337, 239, 128, 102, 232, 429, 3,
98, 43, -141, -77, -13, 125, 361, -45, 184)
x <- ts(x, start = c(1951, 1), end = c(1958, 4), frequency = 4)
m <- decompose(x)
x
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/ApprovActiv.dat"
Build.dat <- read.table(www,header=T); attach(Build.dat)
App.ts <- ts(Approvals, start=c(1996,1), freq=4)
Act.ts <- ts(Activity, start = c(1996,1), freq=4)
# We can use ts.plot to put two time series on the same plot. Here, we look at approvals and activity.
ts.plot(App.ts, Act.ts, lty=c(1,3))
#The ts.union function binds time series with a common frequency, padding with "NAs" to the union of their time coverages. Can use with acf to get a correlogram for the two variables.
acf(ts.union(App.ts,Act.ts))
ts.union(App.ts,Act.ts)
App.ts
Act.ts
ts.union(App.ts,Act.ts)
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/ApprovActiv.dat"
Build.dat <- read.table(www,header=T); attach(Build.dat)
View(Build.dat)
App.ts <- ts(Approvals, start=c(1996,1), freq=4)
App.ts
x <- ts(x, start = c(1951, 1), end = c(1958, 4), frequency = 4)
m <- decompose(x)
x <- c(-50, 175, 149, 214, 247, 237, 225, 329, 729, 809,
530, 489, 540, 457, 195, 176, 337, 239, 128, 102, 232, 429, 3,
98, 43, -141, -77, -13, 125, 361, -45, 184)
deseasonalized <- x - m
x <- c(-50, 175, 149, 214, 247, 237, 225, 329, 729, 809,
530, 489, 540, 457, 195, 176, 337, 239, 128, 102, 232, 429, 3,
98, 43, -141, -77, -13, 125, 361, -45, 184)
x <- ts(x, start = c(1951, 1), end = c(1958, 4), frequency = 4)
m <- decompose(x)
deseasonalized <- x - m
m <- decompose(x)
deseasonalized <- x - m
x
m
x <- c(-50, 175, 149, 214, 247, 237, 225, 329, 729, 809,
530, 489, 540, 457, 195, 176, 337, 239, 128, 102, 232, 429, 3,
98, 43, -141, -77, -13, 125, 361, -45, 184)
x <- ts(x, start = c(1951, 1), end = c(1958, 4), frequency = 4)
m <- decompose(x)
deseasonalized <- x - m
deseasonalized <- x - m$seasonal
deseasonalized
plot(decompose(Elec.ts))
Elec.decom <- decompose(Elec.ts, type = "mult")
plot(Elec.decom)
Seasonal <- Elec.decom$seasonal
elec.deseasoned <- Elec.ts - Seasonal
www <- "http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/cbe.dat"
CBE <- read.table(www,header=T)
CBE[1:4,]
class(CBE)
Elec.quarterly <- aggregate(Elec.ts, nfrequency=4)
Elec.quarterly
Elec.quarterly <- aggregate(elec.deseasoned , nfrequency=4)
Elec.quarterly <- aggregate(Elec.ts, nfrequency=4)
Elec.quarterly2 <- aggregate(elec.deseasoned , nfrequency=4)
Elec.quarterly
Elec.quarterly2
Global.ts
New.series
calc_auc(roc.glm)[,2:3]
svm.rbf.fit <- svm(coverage ~ age + cit, data=train, kernel = "radial",
cost = 1, gamma = 0.05555)
print(svm.rbf.fit)
#Calibrate SVMs
pred.test <- svm(coverage ~ ., data = train, kernel = "radial", cost = 1, gamma = 8)
print(pred.test)
#Predict
pred.rbf <- predict(pred.test, test)
scores <- rbind(scores, data.frame(model = "SVM", d = test$coverage,  m = pred.rbf))
table(pred.rbf)
meanf1(test$coverage, pred.rbf)
library(rpart)
fit.opt <- rpart(coverage ~ .,
method = "class", data = train, cp = 1.0885e-03)
pred.default.test <- predict(fit.opt, test, type='prob')[,2]
scores <- rbind(scores, data.frame(model = "Decision Tree", d = test$coverage,  m = pred.default.test >=0.5))
library(randomForest)
fit.rf <- randomForest(coverage ~ age + wage + cit + mar + educ + race, data = train)
fit.tune <- tuneRF(train[,-1], train$coverage, ntreeTry = 500,
mtryStart = 1, stepFactor = 2,
improve = 0.001, trace = TRUE, plot = TRUE)
tune.param <- fit.tune[fit.tune[, 2] == min(fit.tune[, 2]), 1]
pred.rf.test <- predict(fit.rf, test, type='prob')[,2]
scores <- rbind(scores,
data.frame(model = "rf", d = test$coverage,  m = pred.rf.test >=.5))
scores$m[scores$m == "TRUE"] <- "No Coverage"
scores$m[scores$m == "FALSE"] <- "Coverage"
##################
## KNNs CLASS  ##
library(class)
age <- round(health$age / 10) * 10
age <- factor(age)
#Wage
wage <- round(health$wage / 20000) * 20000
wage[wage > 200000] <- 200000
wage <- factor(wage)
#Convert data into binary
cit <- as.data.frame(model.matrix(~ health$cit - 1)[, 2])
mar <- as.data.frame(model.matrix(~ health$mar - 1)[,1:4])
educ <- as.data.frame(model.matrix(~ health$mar - 1)[,1:4])
race <- as.data.frame(model.matrix(~ health$race - 1)[,1:7])
wage <- as.data.frame(model.matrix(~ wage - 1)[,2:11])
age <- as.data.frame(model.matrix(~ age - 1)[,2:8])
#Combine all the newly transformed data
knn.data <- as.data.frame(cbind(coverage = as.character(health$coverage),
wage, age, cit, educ, mar, race))
#Train-Test
rand <- runif(nrow(knn.data))
rand <- rand > 0.5
#Create x-matrix. Use "-1" in the column argument to keep everything except column 1
xtrain <- knn.data[rand == T, -1]
xtest <- knn.data[rand == F, -1]
#Create y-matrix
ytrain <- knn.data[rand == T, 1]
ytest <- knn.data[rand == F, 1]
pred <- knn(xtrain, xtest, cl = ytrain, k = 30, prob = TRUE)
test.prob <- attr(pred, "prob")
#TPR
pred.class <- test.prob
pred.class[test.prob >= mean(test.prob)] <- "Coverage"
pred.class[test.prob < mean(test.prob)] <- "No Coverage"
scores <- rbind(scores, data.frame(model = "KNN", d = ytest,  m = pred.class))
for(z in unique(scores$model)){
print(paste(z, ": ",  meanf1(scores[scores$model==z,"d"], scores[scores$model==z,"m"])))
}
#Margin Example
margin_size <- 0.3
set.seed(123)
df <- data.frame(x = runif(200),
y = runif(200),
supports = NA)
#Set up margin supports
supports <- data.frame( x = c(0.6, 0.7, 0.7), y = NA, supports = NA)
supports$supports[1:2] <- -1.08 + 2*supports$x[1:2]
supports$supports[3] <- -.52 + 2*supports$x[3]
df <- rbind(df,
supports)
#Best boundary
df$z <- -0.8 + df$x*2
df$perp <- 0.6578033 + df$x*-0.5
df$perp[df$x >= 0.6951213] <- NA
df$perp[df$x <= 0.4711213] <- NA
#Cut out
df <- df[which((df$y > df$z + margin_size | df$y < df$z - margin_size | !is.na(df$supports))), ]
df$group <- "Side A"
df$group[df$y < df$z - margin_size] <- "Side B"
df$cols <- "blue"
df$cols[df$group == "Side B"] <- "green"
#Alternative boundaries
df$z1 <- -1.1 + df$x*2.1
df$z2 <- -0.5 + df$x*1.9
df$z3 <- -0.95 + df$x*2
df$z4 <- -0.65 + df$x*2
df$z5 <- -0.95 + df$x*2.3
df$z6 <- -0.65 + df$x*1.7
df$margin2 <- -1.08 + df$x*2
df$margin1 <- -.52 + df$x*2
df <- df[order(df$perp),]
library(ggplot2)
base <- ggplot(df, aes(group=factor(group))) +
geom_point(aes(x = x, y = y,  colour = factor(group)))  +
ylim(0,1) + xlim(0,1) +
ylab("x1") + xlab("x2") +
ggtitle("(1)") + scale_colour_manual(values=c("lightblue", "lightgrey")) +
coord_fixed(ratio = 1) +
theme(plot.title = element_text(size = 10),
axis.line=element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank(),axis.ticks=element_blank(),
legend.position="none",
panel.background=element_blank(),panel.border=element_blank(),
panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank(),
plot.margin=unit(c(-0.5,1,1,1), "cm"))
options1 <- ggplot(df) +
geom_point(aes(x = x, y = y, colour = df$cols)) +
geom_line(aes(x = x, y = z), alpha = 0.5, colour = "grey") +
geom_line(aes(x = x, y = z1), alpha = 0.5, colour = "grey") +
geom_line(aes(x = x, y = z2), alpha = 0.5, colour = "grey") +
geom_line(aes(x = x, y = z3), alpha = 0.5, colour = "grey") +
geom_line(aes(x = x, y = z4), alpha = 0.5, colour = "grey") +
geom_line(aes(x = x, y = z5), alpha = 0.5, colour = "grey") +
geom_line(aes(x = x, y = z6), alpha = 0.5, colour = "grey") +
ylim(0,1) + xlim(0,1) +
ggtitle("(2)") +  scale_colour_manual(values=c("lightblue", "lightgrey")) +
coord_fixed(ratio = 1) +
ylab("x1") + xlab("x2") +
theme(plot.title = element_text(size = 10),
axis.line=element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank(),axis.ticks=element_blank(),
legend.position="none",
panel.background=element_blank(),panel.border=element_blank(),
panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank(),
plot.margin=unit(c(-0.5,1,1,1), "cm"))
optimal <- ggplot(df) +
geom_point(aes(x = x, y = y, colour = df$cols)) +
geom_line(aes(x = x, y = z), size = 2, colour = "purple") +
geom_line(aes(x = x, y = margin1), size = 1, linetype="dashed", colour = "grey") +
geom_line(aes(x = x, y = margin2), size = 1, linetype="dashed", colour = "grey") +
geom_line(aes(x = x, y = perp), size = 1, colour = "blue") +
ylim(0,1) + xlim(0,1) +
ylab("x1") + xlab("x2") +
ggtitle("(3)") +  scale_colour_manual(values=c("lightblue", "lightgrey")) +
coord_fixed(ratio = 1) +
theme(plot.title = element_text(size = 10),
axis.line=element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank(),axis.ticks=element_blank(),
legend.position="none",
panel.background=element_blank(),panel.border=element_blank(),
panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank(),
plot.margin=unit(c(-0.5,1,1,1), "cm")) +
annotate("text", x = .3, y = .4, label = "Margin", colour = "blue") +
annotate("text", x = .8, y = .2, label = "Hyperplane", colour = "purple")
supports <- ggplot(df) +
geom_point(aes(x = x, y = y, colour = df$cols)) +
geom_line(aes(x = x, y = z), size = 2, colour = "purple") +
geom_line(aes(x = x, y = margin1), size = 1, linetype="dashed", colour = "grey") +
geom_line(aes(x = x, y = margin2), size = 1, linetype="dashed", colour = "grey") +
geom_point(aes(x = x, y = supports, colour = "red", size=0.7)) +
ylim(0,1) + xlim(0,1) +
ylab("x1") + xlab("x2") +
ggtitle("(4)") +  scale_colour_manual(values=c("lightblue", "lightgrey", "red")) +
coord_fixed(ratio = 1) +theme_bw() +
theme(plot.title = element_text(size = 10),
axis.line=element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank(),axis.ticks=element_blank(),
legend.position="none",
panel.background=element_blank(),panel.border=element_blank(),
panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank(),
plot.margin=unit(c(-0.5,1,1,1), "cm"))
grid.arrange(base, options1, ncol = 2)
grid.arrange(optimal, supports, ncol = 2)
#2d
set.seed(100)
x <- rnorm(4000,3,0.2)
y <- rnorm(4000,3,0.2)
xw <- runif(10000)*4
yw <- runif(10000)*4
data <- rbind(data.frame(x = x, y = y, colour = "green"), data.frame(x = xw,y = yw, colour = "grey"))
data$xr <- round(data$x,1)
data$yr <- round(data$y,1)
data$flag <- 1
data$flag[data$colour == "grey"] <- 0
temp <- aggregate(data$flag, by = list(xr = data$xr, yr = data$yr), FUN = mean)
colnames(temp) <- c("xr", "yr", "mean")
data <- merge(data, temp, by = c("xr", "yr"))
data <- data[!(data$flag == 0 & data$mean > 0), ]
data$colour <- as.character(data$colour)
plot(data$x, data$y, col = data$colour, pch = 19, cex = 0.3)
x1 <- seq(-10, 10, length.out = 50)
x2 <- x1
df <- expand.grid(x1, x2)
zf <- function(x,y){x1^2 + x2^2}
z<-outer(x1, x2, zf)
kernel <- persp(x1, x2, z, col = "grey", theta = 30,  phi = -20,
ltheta = -120, shade = 1, border = NA, box = TRUE)
s = sample(1:prod(dim(z)), size=1000)
xx = x1[row(z)[s] ]
yy = x2[col(z)[s]]
zz = z[s] + 10
#2d
set.seed(100)
x <- rnorm(4000,3,0.2)
y <- rnorm(4000,3,0.2)
xw <- runif(10000)*4
yw <- runif(10000)*4
data <- rbind(data.frame(x = x, y = y, colour = "green"), data.frame(x = xw,y = yw, colour = "grey"))
data$xr <- round(data$x,1)
data$yr <- round(data$y,1)
data$flag <- 1
data$flag[data$colour == "grey"] <- 0
temp <- aggregate(data$flag, by = list(xr = data$xr, yr = data$yr), FUN = mean)
colnames(temp) <- c("xr", "yr", "mean")
data <- merge(data, temp, by = c("xr", "yr"))
data <- data[!(data$flag == 0 & data$mean > 0), ]
data$colour <- as.character(data$colour)
plot(data$x, data$y, col = data$colour, pch = 19, cex = 0.3)
x1 <- seq(-10, 10, length.out = 50)
x2 <- x1
df <- expand.grid(x1, x2)
zf <- function(x,y){x1^2 + x2^2}
z<-outer(x1, x2, zf)
kernel <- persp(x1, x2, z, col = "grey", theta = 30,  phi = -20,
ltheta = -120, shade = 1, border = NA, box = TRUE)
s = sample(1:prod(dim(z)), size=1000)
xx = x1[row(z)[s] ]
yy = x2[col(z)[s]]
zz = z[s] + 10
data$colour <- as.character(data$colour)
set.seed(100)
x <- rnorm(4000,3,0.2)
y <- rnorm(4000,3,0.2)
xw <- runif(10000)*4
yw <- runif(10000)*4
data <- rbind(data.frame(x = x, y = y, colour = "green"), data.frame(x = xw,y = yw, colour = "grey"))
data$xr <- round(data$x,1)
data$yr <- round(data$y,1)
data$flag <- 1
data$flag[data$colour == "grey"] <- 0
temp <- aggregate(data$flag, by = list(xr = data$xr, yr = data$yr), FUN = mean)
colnames(temp) <- c("xr", "yr", "mean")
data <- merge(data, temp, by = c("xr", "yr"))
data <- data[!(data$flag == 0 & data$mean > 0), ]
data$colour <- as.character(data$colour)
plot(data$x, data$y, col = data$colour, pch = 19, cex = 0.3)
x1 <- seq(-10, 10, length.out = 50)
x2 <- x1
df <- expand.grid(x1, x2)
zf <- function(x,y){x1^2 + x2^2}
z<-outer(x1, x2, zf)
z<-outer(x1, x2, zf)
depth3d <- function(x,y,z, pmat, minsize=0.2, maxsize=2) {
# determine depth of each point from xyz and transformation matrix pmat
tr <- as.matrix(cbind(x, y, z, 1)) %*% kernel
tr <- tr[,3]/tr[,4]
# scale depth to point sizes between minsize and maxsize
psize <- ((tr-min(tr) ) * (maxsize-minsize)) / (max(tr)-min(tr)) + minsize
return(psize)
}
# determine distance to eye
psize = depth3d(xx,yy,zz,kernel,minsize=0.1, maxsize = 0.3)
mypoints <- trans3d(xx, yy, zz, pmat=kernel)
# plot in 2D space with pointsize related to distance
points(mypoints, pch=19, cex=psize, col=4)
points(mypoints, pch=19, cex=psize, col=4)
