forceNetwork(Links = links, Nodes = nodes,
Source = "source", Target = "target",
Value = "value", NodeID = "name", fontSize = 20,
Group = "group", width = 1000, height = 1000, bounded = F,
opacity = 0.6, linkDistance =10, charge = -900, Nodesize = "x",
colourScale = "d3.scale.category10()")
summary(nodes$x)
nodes$x <- nodes$x*100
Padding
#Padding
setwd("/Users/jeff/Documents/Github/mccourt2018-hwmk/2/")
files <- list.files("student_scripts/raw/")
df <- data.frame()
for(i in files){
a <- readLines(paste0("student_scripts/raw/",i))
a <- a[8:length(a)]
a <- trimws(a)
a <- a[substr(a, 1,1)!= "#"]
name_1 <- gsub("Homework #2 - Looping Galore_", "", i)
name_1 <- substr(name_1, 1, regexpr("_",name_1)-1)
b <- paste(a, collapse = " ")
df <- rbind(df, data.frame(student = name_1, func = tolower(b)))
}
df$func <- as.character(df$func)
df$func.name <- tolower(trimws(substr(df[,2],1,regexpr("*<- | *=", df[,2])-1)))
df$func.len <- nchar(df$func)
df$student <- as.character(df$student)
df <- df[df$func!="",]
#Parse all parts
parts <- unique(unlist(strsplit(df[,2],"[[:punct:][:space:]]")))
parts <- parts[parts != ""]
master <- data.frame()
for(k in 1:nrow(df)){
a <- trimws(unlist(strsplit(df[k,2],"[[:punct:][:space:]]")))
a <- a[a!=""]
b <- aggregate(a, by=list(term = a), FUN = length)
b$author <- df[k,1]
#b$author <- paste0("PERSON = ", round(runif(1)*10000))
master <- rbind(master, b)
}
#Create links
links <- master[, c(3,1,2)]
colnames(links) <- c("source", "target", "value")
#calculate tf_idf
tfidf <- function(df, count.field, term, document){
# Returns TFIDF value
#
# Args:
#   df: data frame
#   count.field: string name of field containing frequency of a every unique word for each document
#   term: string name of the field containing words
#   document: string name of the field containing document ids
#
# Returns:
#   Vector of TFIDF values for each word-document combination
df <- df[,c(count.field, term, document)]
colnames(df) <- c("count","term","doc")
#Total frequency of terms
df$tot_freq <- sum(df$count)
#Number of documents
df$num_docs <- length(unique(df$doc))
#Number of documents with a given term
datatemp <- df[!duplicated(df[,c("doc", "term")]),]
num_doc_term <- aggregate(datatemp$term,
by = list(term = datatemp$term),
FUN = length)
colnames(num_doc_term)[2] <- "num_doc_term"
#merge
df <- merge(df, num_doc_term, by = "term", all.x = T)
#compute
df$tfidf <- (df$count/df$tot_freq) * log(df$num_docs / df$num_doc_term)
df <- df[, c("count","term", "doc", "tfidf")]
colnames(df) <- c(count.field, term, document, "tfidf")
return(df)
}
test <- rbind(data.frame(var = links$source, x = links$value),
data.frame(var = links$target, x = links$value))
test1 <- aggregate(test$x, by = list(tolower(test$var)), FUN = sum)
test1 <- test1[test1$x > 2, 1]
links <- links[links$source %in% test1,]
links <- links[links$target %in% test1,]
links  <- tfidf(links, "value", "target", "source")
links$value <- NULL
colnames(links)[3] <- "value"
c <- aggregate(links$value, by = list(name = links$source), FUN = sum)
d <- aggregate(links$value, by = list(name = links$target), FUN = sum)
e <- rbind(c, d)
nodes <- data.frame(name = c(unique(links$source),unique(links$target)),
group = c(rep(1,length(unique(links$source))),rep(2,length(unique(links$target))) ))
nodes$name <- as.character(nodes$name)
nodes <- merge(nodes, e, id = "name")
links[,1] <-as.character(links[,1])
links[,2] <-as.character(links[,2])
nodes[,1] <-as.character(nodes[,1])
nodes$rank <- 1:nrow(nodes)
nodes$rank <- nodes$rank-1
links <- merge(links, nodes[,c("name","rank")], by.x = "source", by.y = "name", all.x =T)
links <- merge(links, nodes[,c("name","rank")], by.x = "target", by.y = "name", all.x =T)
links <- links[,c(4,5,3)]
colnames(links) <- c("source", "target", "value")
links$value <- 5*(links$value/max(links$value))/(1 -(links$value/max(links$value)))
links <- links[links$value != 0 & links$value!= Inf,]
links <- links[order(links[,1]),]
nodes$x <- nodes$x*100
nodes$x
pos <- c(4,5,10,11)
y <- 2^pos
y1 <- 2.5^pos
(y1/y-1)
mean(abs((y1/y-1))
mean(abs((y1/y-1)))
pos <- c(4,5,10,11)
y <- 2^pos
y1 <- 3^pos
mean(abs((y1/y-1)))
pos <- c(4,5,10,11)
y <- 2^pos
y1 <- 2.1^pos
mean(abs((y1/y - 1)))
pos <- c(4,5,10,11)
y <- 2^pos
y1 <- 2.05^pos
mean(abs((y1/y - 1)))
pos <- c(4,5,10,11)
y <- 2^pos
y1 <- 2^pos
mean(abs((y1/y - 1)))
pos <- c(4,5,10,11)
y <- 2^pos
y1 <- 2.01^pos
mean(abs((y1/y - 1)))
pos <- c(10:12)
y <- 2^pos
y1 <- 2.01^pos
mean(abs((y1/y - 1)))
pos <- c(1:3)
y <- 2^pos
y1 <- 2.01^pos
mean(abs((y1/y - 1)))
pos <- c(4:6)
y <- 2^pos
y1 <- 2.01^pos
mean(abs((y1/y - 1)))
pos <- c(7:8)
y <- 2^pos
y1 <- 2.01^pos
mean(abs((y1/y - 1)))
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 1.9^pos
return(mean(abs((y1/y - 1))))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4), collapse = " + "
)
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 1.9^pos
return(round(mean(abs((y1/y - 1))),1))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4), collapse = " + ")
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 1.9^pos
return(round(mean(abs((y1/y - 1))),1))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4), collapse = " + ")
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4), collapse = " + ")
mape(pos1)
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 1.9^pos
return(round(mean(abs((y1/y - 1))),2))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4), collapse = " + ")
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 2^pos
return(round(mean(abs((y1/y - 1))),2))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4), collapse = " + ")
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 2.01^pos
return(round(mean(abs((y1/y - 1))),2))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4), collapse = " + ")
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 1.9^pos
return(round(mean(abs((y1/y - 1))),2))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4), collapse = " + ")
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 1.9^pos
return(round(mean(abs((y1/y - 1))),2))
}
mean(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 2.01^pos
return(round(mean(abs((y1/y - 1))),2))
}
mean(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 2.01^pos
return(paste0(round(100*mean(abs((y1/y - 1))),1), "%"))
}
mean(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
mean(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 2.01^pos
return(round(100*mean(abs((y1/y - 1))),))
}
mean(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
mean(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 2.01^pos
return(round(100*mean(abs((y1/y - 1))),1))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
mean(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 1.9^pos
return(round(100*mean(abs((y1/y - 1))),1))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
mean(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 1.9^pos
return(round(100*mean(abs((y1/y - 1))),1))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
sd(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 1.9^pos
return(round(100*mean(abs((y1/y - 1))),1))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
sd(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
sd(c(mape(pos1), mape(pos2), mape(pos3), mape(pos4)))
sd(c(mape(pos1), mape(pos2), mape(pos3), mape(pos4)))*2
pos1 <- 1:3
pos2 <- 4:6
pos3 <- 7:9
pos4 <- 10:12
mape <- function(pos){
y <- 2^pos
y1 <- 2.01^pos
return(round(100*mean(abs((y1/y - 1))),1))
}
paste(mape(pos1), mape(pos2), mape(pos3), mape(pos4))
sd(c(mape(pos1), mape(pos2), mape(pos3), mape(pos4)))
sd(c(mape(pos1), mape(pos2), mape(pos3), mape(pos4)))*2
#EXAMPLE 1 -- OLS
#Read in file
dir <- "/Users/jeff/Documents/Github/data-science/lecture-05/data"
setwd(dir)
df <- read.csv("tollroad_ols.csv")
#Check file
str(df[1:3,])
df$date <- as.Date(df$date, "%Y-%m-%d")
df$fips <- factor(df$fips)
#Check correlations
tab <- cor(log(df[,c(4:8)]), use = "complete")
#Set training/testing
df$flag <- 0
df$flag[
##########################
##LECTURE 5: OLS Example##
##########################
#EXAMPLE 1 -- OLS
#Read in file
dir <- "/Users/jeff/Documents/Github/data-science/lecture-05/data"
setwd(dir)
df <- read.csv("tollroad_ols.csv")
#Check file
str(df[1:3,])
df$date <- as.Date(df$date, "%Y-%m-%d")
df$fips <- factor(df$fips)
#Check correlations
tab <- cor(log(df[,c(4:8)]), use = "complete")
#Set training/testing
df$flag <- 0
df$flag[df$year >= 2015] <- 1
#Run LM, v1
fit <- lm( log(transactions) ~ log(emp), data = df[df$flag == 0,])
summary(fit)
#Check coefficient
summary(fit)$coef
summary(fit)$r.squared
str(summary(fit))
#Check errors
library(ggplot2)
x <- data.frame(resid = fit$residuals)
set.seed(50)
x$norm <- rnorm(nrow(x), mean(x$resid), sd(x$resid))
ggplot(x, aes(resid)) +
geom_density(aes(norm), alpha = 0.4, fill = "yellow") +
geom_density(fill = "navy", alpha = 0.6)
#LM v2
fit <- lm(log(transactions) ~ log(emp) + log(bldgs) + log(wti_eia) + fips,
data = df[df$flag == 0,])
summary(fit)
#Check errors
x <- data.frame(resid = fit$residuals)
set.seed(50)
x$norm <- rnorm(nrow(x), mean(x$resid), sd(x$resid))
ggplot(x, aes(resid)) +
geom_density(aes(norm), alpha = 0.4, fill = "yellow") +
geom_density(fill = "navy", alpha = 0.6)
#Predict
df$yhat <- predict(fit, newdata = df)
mape <- function(y_hat, y){
return(mean(abs(y_hat/y-1), na.rm=T))
}
#Check train versus test
#train error
train_error <- mape(df[df$flag == 0, "yhat"], log(df[df$flag == 0, "transactions"]))
#test error
test_error <- mape(df[df$flag == 1, "yhat"], log(df[df$flag == 1, "transactions"]))
ggplot(x, aes(resid)) +
geom_density(aes(norm), alpha = 0.4, fill = "yellow") +
geom_density(fill = "navy", alpha = 0.6)
#EXAMPLE 1 -- OLS
#Read in file
dir <- "/Users/jeff/Documents/Github/data-science/lecture-05/data"
setwd(dir)
df <- read.csv("tollroad_ols.csv")
#Check file
str(df[1:3,])
df$date <- as.Date(df$date, "%Y-%m-%d")
df$fips <- factor(df$fips)
#Check correlations
tab <- cor(log(df[,c(4:8)]), use = "complete")
#Set training/testing
df$flag <- 0
df$flag[df$year >= 2015] <- 1
#Run LM, v1
fit <- lm( log(transactions) ~ log(emp), data = df[df$flag == 0,])
summary(fit)
#Check coefficient
summary(fit)$coef
summary(fit)$r.squared
str(summary(fit))
#Check errors
library(ggplot2)
x <- data.frame(resid = fit$residuals)
set.seed(50)
x$norm <- rnorm(nrow(x), mean(x$resid), sd(x$resid))
#Graph errors to check for normality
ggplot(x, aes(resid)) +
geom_density(aes(norm), alpha = 0.4, fill = "yellow") +
geom_density(fill = "navy", alpha = 0.6)
#LM v2
fit <- lm(log(transactions) ~ log(emp) + log(bldgs) + log(wti_eia) + fips,
data = df[df$flag == 0,])
summary(fit)
#Check errors
x <- data.frame(resid = fit$residuals)
set.seed(50)
x$norm <- rnorm(nrow(x), mean(x$resid), sd(x$resid))
ggplot(x, aes(resid)) +
geom_density(aes(norm), alpha = 0.4, fill = "yellow") +
geom_density(fill = "navy", alpha = 0.6)
#Predict
df$yhat <- predict(fit, newdata = df)
mape <- function(y_hat, y){
return(mean(abs(y_hat/y-1), na.rm = T))
}
#Check train versus test
#train error
train_error <- mape(df[df$flag == 0, "yhat"], log(df[df$flag == 0, "transactions"]))
#test error
test_error <- mape(df[df$flag == 1, "yhat"], log(df[df$flag == 1, "transactions"]))
train_error
test_error
#Load library
library(gtrendsR)
library(ggplot2)
#Download human rights for
out = gtrends(c("Human rights"), gprop = "web", time =  "2011-01-01 2017-01-01")[[1]]
#Monthly line plot
ggplot(out, aes(date, hits)) + geom_line()
#Monthly dummies
month = format(out$date, "%m")
dummies = model.matrix(~ month)
colnames(dummies)
#Date Index
date.index <- 1:nrow(out)
#Create matrix
X <- cbind(dummies[, -13], date.index)
head(X)
y <- out$hits
a <- t(X) %*% X
w <- solve(a) %*% t(X) %*% y
#Run lm()
lm.obj <- lm(y ~ X[,-1])
#Consolidate and compare model coefficients
comparison <- data.frame(`From Scratch` = w,
`lm Function` = coef(lm.obj))
#Print
print(comparison)
out
out = gtrends(c("Human rights"), gprop = "web", time =  "2011-01-01 2017-01-01")[[1]]
#Load library
library(gtrendsR)
library(ggplot2)
#Download human rights for
out = gtrends(c("Human rights"), gprop = "web", time =  "2011-01-01 2017-01-01")[[1]]
out = gtrends(c("Human rights"), gprop = "web", time =  "2011-01-01 2017-01-01")
out = gtrends(c("Amazon"), gprop = "web", time =  "2011-01-01 2017-01-01")[[1]]
out = gtrends(c("Amazon"), gprop = "news", time =  "2011-01-01 2017-01-01")[[1]]
out = gtrends(c("Amazon"), gprop = "news", time =  "2011-01-01 ")
out = gtrends(c("Amazon"), gprop = "news", time =  "2011-01-01")
out = gtrends(c("Amazon"), gprop = "news", start_date =  "2011-01-01")
out = gtrends(c("Amazon"), gprop = "news", time =  "2011-01-01 2017-01-01")[[1]]
#Load library
library(gtrendsR)
library(ggplot2)
#Download human rights for
out = gtrends(c("Amazon"), gprop = "news", time =  "2011-01-01 2017-01-01")[[1]]
#Monthly line plot
ggplot(out, aes(date, hits)) + geom_line()
#Monthly dummies
month = format(out$date, "%m")
dummies = model.matrix(~ month)
colnames(dummies)
#Date Index
date.index <- 1:nrow(out)
#Create matrix
X <- cbind(dummies[, -13], date.index)
head(X)
y <- out$hits
#Matrix multiply XT by X
a <- t(X) %*% X
#Solve for inverse of a
w <- solve(a) %*% t(X) %*% y
#Run lm()
lm.obj <- lm(y ~ X[,-1])
#Consolidate and compare model coefficients
comparison <- data.frame(`From Scratch` = w,
`lm Function` = coef(lm.obj))
#Print
print(comparison)
