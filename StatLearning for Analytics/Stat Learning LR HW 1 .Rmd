---
title: "StateLearning HW 1"
author: "Christian Conroy"
date: "Feb 7th, 2018"
output: html_notebook
---

```{r setup, include=FALSE}
require(knitr)
require(ISLR)


opts_chunk$set(echo = TRUE)
options(digits = 3)

opts_knit$set(root.dir ="/Users/chris/Documents/GeorgetownMPPMSFS/McCourtMPP/Semester 6 Spring 2019/StatLearning for Analytics")
```

# 1. (3 pts) Textbook #3.7.3

3. Suppose we have a data set with five predictors, X1 = GPA, X2 = IQ,
X3 = Gender (1 for Female and 0 for Male), X4 = Interaction between
GPA and IQ, and X5 = Interaction between GPA and Gender. The
response is starting salary after graduation (in thousands of dollars).
Suppose we use least squares to fit the model, and get ??^0 = 50, ??^1 =
20, ??^2 = 0.07, ??^3 = 35, ??^4 = 0.01, ??^5 = ???10.

(a) Which answer is correct, and why?

i. For a fixed value of IQ and GPA, males earn more on average
than females.
ii. For a fixed value of IQ and GPA, females earn more on
average than males.
iii. For a fixed value of IQ and GPA, males earn more on average
than females provided that the GPA is high enough.
iv. For a fixed value of IQ and GPA, females earn more on
average than males provided that the GPA is high enough.

iii is the correct answer. For a fixed value of IQ and GPA, males earn more on average
than females provided that the GPA is high enough. When IQ and GPA are fixed, then the difference between males and females is demonstrated by B3 + B5. While B3 indicates that females earn more on average than males at a theoretical GPA of 0, the negative coefficient on B5 indicates that females on average will only earn more on average than males at lower GPAs but that males will earn more on average than females as the GPA surpassesapproximately 3.5. 

(b) Predict the salary of a female with IQ of 110 and a GPA of 4.0.

```{r message = FALSE}
50 + (20*4) + (.07*110) + (35*1) + (.01*4*110) + (-10*1*4)
```

The predicted salary of a female with IQ of 110 and a GPA of 4.0 is $137,000. 

(c) True or false: Since the coefficient for the GPA/IQ interaction
term is very small, there is very little evidence of an interaction
effect. Justify your answer.

False. While the coefficient may indicate that the magnitude of the GPA/IQ interaction term is small, we would need to examine the hypothesis test with a null that B4 = 0 to determine whether there is evidence of an interaction effect. Specifically, we can examine whether the p-value is lower than 0.05 (95% confidence level) or potentially .10 (90% confidence level) depending on what threshold we apply. This is the same as observing whether the t statistic falls outside of the critical value in absolute value terms. This is all to say that we can only determine if there is evidence of an interaction effect by assessing whether the coefficient is statistically significant. 

# 2. (3 pts) Textbook #3.7.8

8. This question involves the use of simple linear regression on the Auto
data set.

(a) Use the lm() function to perform a simple linear regression with
mpg as the response and horsepower as the predictor. Use the
summary() function to print the results. 

```{r message = FALSE}
data("Auto")
head(Auto)
```

```{r message = FALSE}
reg1 <- lm(mpg ~ horsepower, data = Auto)
summary(reg1)
```

Comment on the output.
For example:
122 3. Linear Regression
i. Is there a relationship between the predictor and the response?

According to the results of our regression analysis, there appears to be a relationship between the predictor and the response. The coefficient of -0.15785 indicates a negative relationship between horsepower and mpg and the low p-value indicates that the coefficient is statistically significant at the 99% confidence level. However, it is important to note that this is only a univariate regression model and it therefore may suffer from endogeneity. We can conclude a correlation but we cannot conclude causation. 

ii. How strong is the relationship between the predictor and
the response?

The magnitude is fairly small, indicating that a unit increase in horsepower only slightly impacts the mpg of the vehicle. It would take much larger changes in the horsepower to have any larger magnitude effect. Again, according to the model, this is a statistically significant effect. 


iii. Is the relationship between the predictor and the response
positive or negative?

The relationship between the predictor and the response variable is negative. 

iv. What is the predicted mpg associated with a horsepower of
98? What are the associated 95 % confidence and prediction
intervals?

```{r message = FALSE}

confint(reg1)
predict(reg1, data.frame(horsepower=98), interval="predict") 

```

The predicted mpg associated with a horsepower of 98 is 24.5 with a prediction interval of 14.8 to 34.1. The 95% confidence interval for the horsepower coefificent is -0.171 to -0.145. 


(b) Plot the response and the predictor. Use the abline() function
to display the least squares regression line.

```{r message = FALSE}
plot(Auto$horsepower,Auto$mpg, xlab = "Horsepower", ylab = "Predicted MPG")
abline(a = coef(reg1)[1], b = coef(reg1)[2], col = 2)
```


(c) Use the plot() function to produce diagnostic plots of the least
squares regression fit. Comment on any problems you see with
the fit.

```{r message = FALSE}

plot(reg1)

```

# 3. (3 pts) Extra #4

a) Modify the function myclosest() so that it uses exactly k neighbors instead of 100 to classify a test
digit. The new function should have two arguments, namely mydigit and k.

b) Demonstrate the modified function by trying to classify a test digit of your choice. Find a value of k
such that the classification is correct and another value of k < 1000 such that the classification of the
same test digit is incorrect.

```{r message = FALSE}
data <- load("mnist_all.Rdata")

# predict a digit from the MNIST training set from the most frequent digit
# among the 100 closest neighbors in the training set
myclosest = function(mydigit, k){
digit.dist = function(j){
return(sqrt(mean((test$x[mydigit,] - train$x[j,])^2) ) )
}
mnist.distances = sapply(1:60000,FUN = digit.dist)
myclosest = head(order(mnist.distances),k)
mytable <- table(train$y[myclosest])
myindex = which.max(mytable)
return(as.numeric(names(mytable[myindex])))
}
# Try it. Prediction and actual value of digit 234 in the test set

# Correct Classification
c(test$y[160], myclosest(160, 100))
# Incorrect Classification
c(test$y[160], myclosest(160, 500))
# Come back to

```

# 4. (5 pts) Textbook #2.4.8

(b) Look at the data using the fix() function. You should notice
that the first column is just the name of each university. We don't
really want R to treat this as data. However, it may be handy to
have these names for later. Try the following commands:

```{r message = FALSE}
data("College")
head(College)
write.csv(College, "College.csv")
college <- read.csv('College.csv', header = TRUE)

rownames(college) = college[,1]
fix(college)

college = college[,-1]
fix(college)
```

(c) i. Use the summary() function to produce a numerical summary
of the variables in the data set.

```{r message = FALSE}
summary(college)

```

ii. Use the pairs() function to produce a scatterplot matrix of
the first ten columns or variables of the data. Recall that
you can reference the first ten columns of a matrix A using
A[,1:10].

```{r message = FALSE}

pairs(college[,1:10])

```

iii. Use the plot() function to produce side-by-side boxplots of
Outstate versus Private.

```{r echo = FALSE, message = FALSE}
boxplot(Outstate ~ Private, data = college, xlab = "Private", ylab = "Number of Outstate")
```

iv. Create a new qualitative variable, called Elite, by binning
the Top10perc variable. We are going to divide universities
into two groups based on whether or not the proportion
of students coming from the top 10 % of their high school
classes exceeds 50 %.

Use the summary() function to see how many elite universities there are. Now use the plot() function to produce
side-by-side boxplots of Outstate versus Elite.

```{r tidy = FALSE}
college$Elite <- ifelse((college$Top10perc > 50), 1, 0)
summary(factor(college$Elite))
```

```{r echo = FALSE, message = FALSE}
boxplot(Outstate ~ Elite, data = college, xlab = "Elite", ylab = "Number of Outstate")
```

v. Use the hist() function to produce some histograms with differing numbers of bins for a few of the quantitative variables. You may find the command par(mfrow=c(2,2)) useful: it will divide the print window into four regions so that four plots can be made simultaneously. Modifying the arguments
to this function will divide the screen in other ways.

```{r echo = FALSE, message = FALSE}
par(mfrow=c(2,2))
hist(college$Apps, xlab = "Number Applied")
hist(college$Accept, xlab = "Number Accepted")
hist(college$Enroll, xlab = "Number Enrolled")
hist(college$Room.Board, xlab = "Room and Board Cost")
```

vi. Continue exploring the data, and provide a brief summary of what you discover

```{r tidy = FALSE}
cor(college[-c(1, 19)])
```

There are some interesting correlations within the data that might be worth looking further into. While it makes sense that schools that receive more applicants would accept more (0.9435), it is surprising that there is such a strong relationship between out of state and expenditures. Perhaps schools that are getting more out of state tuitions and thereby charging more out of state tuition end up making things more expensive because they feel the out of state student population that already pays high tuition can afford it. It is equally interesting to see areas where the correlations are not strong when one would expect them to be. For example, one would expect that people might be deterred from going to a university with a high room and board cost. However, not only is this not the case, but the correlation indicates that there is a slight positive correlation, though not one strong enough to necessarily require further analysis. 

5. (5 pts) Extra #6 

This problem uses the Shiny app at https://keeganhines.shinyapps.io/bias_variance/ . Before working on
this problem, load the app, read the explanation, play with the slider and the "Generate New Data" button,
and answer the questions at the bottom of the page ("Check your understanding") for yourself or discuss
them with others.

Model complexity = degree of the polynomial that is being fitted.

Check your understanding:
What the pros and cons of using functions of high and low complexity?

Functions of high complexity make the model more flexible and able to deal with potential non-linear patterns in the data. However, the risk is that we end up fitting the model perfectly to the sample or training dataset we are using while simultaneously making it less likely to fit another sample or training dataset we might draw from the same population. The benefit of low complexity therefore is that it will be more generalizable across different samples drawn from the same population. 

Would an Order-1 model have high or low bias? High or low variance?

An order-1 model would have high bias but low variance. 

Would an Order-15 model have high or low bias? High or low variance?

An order-15 model with have low bias but high variance. 

a) Make 10 different simulations with model complexity = 1. Compute the average Residual SSE and find
the approximate range of the highest order coefficient for these 10 simulations. This is a measure for
the baseline variance for a low complexity model.

Residual SSE Calcs
Simulation 1: 43.12 
Simulation 2: 98.79 
simulation 3: 123.02 
Simulation 4: 136.62 
Simulation 5: 83.12 
simulation 6: 96.14 
Simulation 7: 132.32 
Simulation 8: 66.42 
simulation 9: 120.58 
Simulation 10: 115.82 

b) Make 10 different simulations with model complexity = 10. Compute the average Residual SSE. Which
coefficient has the largest range in this case? What is that range? This is a measure for the variance
for a high complexity model.

Residual SSE Calcs and Range of Highest Order Coefficient
Simulation 1: 27.23 
Simulation 2: 10.57 
simulation 3: 21.61 
Simulation 4: 21.34 
Simulation 5: 24.57 
simulation 6: 36.87  
Simulation 7: 14.5 
Simulation 8: 30.9 
simulation 9: 3.68 
Simulation 10: 10.33 

The fifth order coefficient appears to has the largest range, with a minimum of -10000 and maximum of 8000, or a range of 18000

c) How do your results illustrate the bias - variance trade-off? The answer should be a short paragraph.

The results illustrate the bias-variance trade-off because although the residual SSE tends to be lower in the model with 10-order complexity, indicating lower bias, there is also a much higher range for coefficient values across the simulations, indicating a higher variance. 

d) For which model complexity between 1 and 15 do you typically obtain a curve which is most similar
and overall close to the unknown curve that is to be estimated? Try multiple simulation for several
different model complexities, summarize what you see, and explain your answer. Pictures or numerical
results are not required.

Model complexity =3 appears to opbtain the curve that is most similar to the unknown curve. Even as we generate new data, the blue curve continues to appear alongside the black curve with relative proximity. 